{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "cortex-nuclei-count-please"
   },
   "source": [
    "# Visualize blobs (nuclei) found in julia and remove misslabeld ones\n",
    "\n",
    "This notebook aids filtering-out and manually selecting mis-detected nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "cortex-nuclei-count-please"
   },
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "import random\n",
    "%gui qt\n",
    "import sys\n",
    "import yaml\n",
    "sys.path.append('..')\n",
    "from calcium_roi_analysis.io import load_tiffstack\n",
    "from calcium_roi_analysis.params import prepare_paths_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "source": [
    "## Prepare paths\n",
    "\n",
    "⚠️ Most inputs come from file \"../current.yaml\". Place a `current.yaml` file in the parent directory of this notebook. See example files in the repository. The only variable controlled here is **review_only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "outputs": [],
   "source": [
    "review_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "outputs": [],
   "source": [
    "params, data_path, output_path = prepare_paths_3d(\"../parameters/current.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "source": [
    "## Load pre-saved volumes of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs  --  ['/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z001_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z002_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z003_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z004_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z005_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z006_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z007_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z008_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z009_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z010_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z011_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z012_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z013_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z014_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z015_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z016_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z017_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z018_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z019_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z020_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z021_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z022_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z023_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z024_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z025_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z026_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z027_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z028_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z029_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z030_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z031_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z032_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z033_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z034_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z035_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z036_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z037_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z038_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z039_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z040_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z041_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z042_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z043_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z044_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z045_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z046_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z047_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z048_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z049_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z050_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z051_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z052_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z053_c001.tif', '/Users/mrestrep/projects/borton/calacium_images/sophie_data/tiffs/Microglia_Sample_2channel_z054_c001.tif']\n"
     ]
    }
   ],
   "source": [
    "voi = load_tiffstack(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "outputs": [],
   "source": [
    "blob_sigmas = [round(x) for x in params[\"radius\"]/np.sqrt(2.)]\n",
    "sigma_string = \"-\".join(map(str,blob_sigmas)).replace(\".\", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "source": [
    "## Load pre-combuted Julia blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "outputs": [],
   "source": [
    "blobs_file = output_path + f\"/blobs-data-{ sigma_string }.npz\"\n",
    "all_blobs_data = np.load(blobs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "outputs": [],
   "source": [
    "points = all_blobs_data['coords']\n",
    "class_labels = all_blobs_data['class_label']  \n",
    "confidence = all_blobs_data['confidence']\n",
    "properties = {\n",
    "    'confidence': confidence,\n",
    "    'good_point': class_labels\n",
    "}\n",
    "confidence_t = float(all_blobs_data['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "outputs": [],
   "source": [
    "sigma = all_blobs_data['sigma']\n",
    "# min_amplitude = min(all_blobs[:, 3])\n",
    "# max_amplitude = max(all_blobs[:, 3])\n",
    "# intensity = (all_blobs[:, 3]-min_amplitude)/max_amplitude\n",
    "# intensity = intensity.reshape((all_blobs[:, 3].shape[0], 1))\n",
    "# points = np.concatenate((intensity, all_blobs[roi_idx][:, 0:3]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.94969042e-06,  4.48597694e-08,  1.98018343e-06, ...,\n",
       "       -5.98148776e-07, -2.57177409e-06,  4.65723868e-06])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "source": [
    "# Adjust class labels\n",
    "\n",
    "1. Use key bindings to increase and decrease threshold:\n",
    "    * y +0.0001; u +0.001; i + 0.01\n",
    "    * t -0.0001; r -0.001; e - 0.01\n",
    "2. Toggle class of points by selecting them and pressing `c` \n",
    "3. You can add and remove points using Napari's lateer tools\n",
    "4. Once you are satisfied press `f` to save results to file\n",
    "5. You can press `h` to toggle show/hide bad(blue) points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "cortex-nuclei-count"
   },
   "outputs": [],
   "source": [
    "if not review_only:\n",
    "    viewer = napari.view_image(voi, rgb=False)\n",
    "\n",
    "    # define the color cycle for the face_color annotation\n",
    "    face_color_cycle = [[0, 0, 1, 0.5], [0, 1, 0, 0.5]]\n",
    "    show_bad_points=True\n",
    "\n",
    "    points_layer = viewer.add_points(points,\n",
    "                        face_color='good_point',\n",
    "                        face_color_cycle=face_color_cycle,\n",
    "                        edge_color=[1, 1, 1, 0],\n",
    "                        name='all_points',\n",
    "                        size=sigma,\n",
    "                        properties=properties)\n",
    "\n",
    "    # bind a function to toggle the good_point annotation of the selected points\n",
    "    @viewer.bind_key('y')\n",
    "    def increase_threshold(viewer):\n",
    "        print(\"bye\")\n",
    "        global confidence_t\n",
    "        print(confidence_t)\n",
    "        confidence_t  = confidence_t + 0.0001\n",
    "        points_layer.properties['good_point'] = points_layer.properties['confidence'] > confidence_t\n",
    "\n",
    "        # we need to manually refresh since we did not use the Points.properties setter\n",
    "        # to avoid changing the color map if all points get toggled to the same class,\n",
    "        # we set update_colors=False (only re-colors the point using the previously-determined color mapping).\n",
    "        points_layer.refresh_colors(update_color_mapping=False)\n",
    "\n",
    "    # bind a function to toggle the good_point annotation of the selected points\n",
    "    @viewer.bind_key('t')\n",
    "    def decrease_threshold(viewer):\n",
    "        print(\"bye\")\n",
    "        global confidence_t\n",
    "        print(confidence_t)\n",
    "        confidence_t  = confidence_t -  0.0001\n",
    "        points_layer.properties['good_point'] = points_layer.properties['confidence'] > confidence_t\n",
    "\n",
    "        # we need to manually refresh since we did not use the Points.properties setter\n",
    "        # to avoid changing the color map if all points get toggled to the same class,\n",
    "        # we set update_colors=False (only re-colors the point using the previously-determined color mapping).\n",
    "        points_layer.refresh_colors(update_color_mapping=False)\n",
    "\n",
    "    # bind a function to toggle the good_point annotation of the selected points\n",
    "    @viewer.bind_key('u')\n",
    "    def increase_threshold(viewer):\n",
    "        print(\"bye\")\n",
    "        global confidence_t\n",
    "        print(confidence_t)\n",
    "        confidence_t  = confidence_t + 0.001\n",
    "        points_layer.properties['good_point'] = points_layer.properties['confidence'] > confidence_t\n",
    "\n",
    "        # we need to manually refresh since we did not use the Points.properties setter\n",
    "        # to avoid changing the color map if all points get toggled to the same class,\n",
    "        # we set update_colors=False (only re-colors the point using the previously-determined color mapping).\n",
    "        points_layer.refresh_colors(update_color_mapping=False)\n",
    "\n",
    "    # bind a function to toggle the good_point annotation of the selected points\n",
    "    @viewer.bind_key('r')\n",
    "    def decrease_threshold(viewer):\n",
    "        print(\"bye\")\n",
    "        global confidence_t\n",
    "        print(confidence_t)\n",
    "        confidence_t  = confidence_t -  0.001\n",
    "        points_layer.properties['good_point'] = points_layer.properties['confidence'] > confidence_t\n",
    "\n",
    "        # we need to manually refresh since we did not use the Points.properties setter\n",
    "        # to avoid changing the color map if all points get toggled to the same class,\n",
    "        # we set update_colors=False (only re-colors the point using the previously-determined color mapping).\n",
    "        points_layer.refresh_colors(update_color_mapping=False)\n",
    "\n",
    "    # bind a function to toggle the good_point annotation of the selected points\n",
    "    @viewer.bind_key('i')\n",
    "    def increase_threshold(viewer):\n",
    "        print(\"bye\")\n",
    "        global confidence_t\n",
    "        print(confidence_t)\n",
    "        confidence_t  = confidence_t + 0.01\n",
    "        points_layer.properties['good_point'] = points_layer.properties['confidence'] > confidence_t\n",
    "\n",
    "        # we need to manually refresh since we did not use the Points.properties setter\n",
    "        # to avoid changing the color map if all points get toggled to the same class,\n",
    "        # we set update_colors=False (only re-colors the point using the previously-determined color mapping).\n",
    "        points_layer.refresh_colors(update_color_mapping=False)\n",
    "\n",
    "    # bind a function to toggle the good_point annotation of the selected points\n",
    "    @viewer.bind_key('e')\n",
    "    def decrease_threshold(viewer):\n",
    "        print(\"bye\")\n",
    "        global confidence_t\n",
    "        print(confidence_t)\n",
    "        confidence_t  = confidence_t -  0.01\n",
    "        points_layer.properties['good_point'] = points_layer.properties['confidence'] > confidence_t\n",
    "\n",
    "        # we need to manually refresh since we did not use the Points.properties setter\n",
    "        # to avoid changing the color map if all points get toggled to the same class,\n",
    "        # we set update_colors=False (only re-colors the point using the previously-determined color mapping).\n",
    "        points_layer.refresh_colors(update_color_mapping=False)\n",
    "\n",
    "    @viewer.bind_key('d')\n",
    "    def decrease_threshold(viewer):\n",
    "        print(\"bye\")\n",
    "        global confidence_t\n",
    "        print(confidence_t)\n",
    "        confidence_t  = confidence_t -  0.01\n",
    "        points_layer.properties['good_point'] = points_layer.properties['confidence'] > confidence_t\n",
    "\n",
    "        # we need to manually refresh since we did not use the Points.properties setter\n",
    "        # to avoid changing the color map if all points get toggled to the same class,\n",
    "        # we set update_colors=False (only re-colors the point using the previously-determined color mapping).\n",
    "        points_layer.refresh_colors(update_color_mapping=False)\n",
    "\n",
    "    # bind a function to toggle the good_point annotation of the selected points\n",
    "    @viewer.bind_key('c')\n",
    "    def toggle_class(viewer):\n",
    "        selected_points = np.array(list(points_layer.selected_data))\n",
    "        if len(selected_points) > 0:\n",
    "            print(f\"Toggling {len(selected_points)} points\")\n",
    "            good_point = points_layer.properties['good_point']\n",
    "            good_point[selected_points] = ~good_point[selected_points]\n",
    "            points_layer.properties['good_point'] = good_point\n",
    "            points_layer.refresh_colors(update_color_mapping=False)\n",
    "\n",
    "    # bind a function to hide the bad (blue - points)\n",
    "    @viewer.bind_key('h')\n",
    "    def hide_bad_points(viewer):\n",
    "        global show_bad_points\n",
    "        if show_bad_points:\n",
    "            points_layer.face_color_cycle = [[0, 0, 1, 0], [0, 1, 0, 1]]\n",
    "            show_bad_points = False\n",
    "        else:\n",
    "            points_layer.face_color_cycle = [[0, 0, 1, 1], [0, 1, 0, 1]]\n",
    "            show_bad_points = True\n",
    "            \n",
    "            \n",
    "    @viewer.bind_key('f')\n",
    "    def save_points(viewer):\n",
    "\n",
    "        print(\"Saving labeled points to file\")\n",
    "        #save results to files.\n",
    "\n",
    "        fout = output_path + \"/curated_blobs.npz\"\n",
    "        np.savez(fout, coords=points_layer.data, class_label=points_layer.properties['good_point'], \n",
    "                       size=points_layer.size, confidence=points_layer.properties['confidence'],\n",
    "                       threshold=[confidence_t])\n",
    "\n",
    "        print(\"Saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload and visualize class labels for verification\n",
    "\n",
    "You can still toggle class, add/remove points using napari's point-layer interface and resave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_blobs_file = output_path  + \"/curated_blobs.npz\"\n",
    "curated_roi = np.load(curated_blobs_file)\n",
    "review_points = curated_roi['coords']\n",
    "class_labels = curated_roi['class_label']    \n",
    "review_properties = {\n",
    "    'confidence': curated_roi['confidence'],\n",
    "    'good_point': class_labels\n",
    "}\n",
    "confidence_t = curated_roi['threshold'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the color cycle for the face_color annotation\n",
    "show_bad_points=True\n",
    "face_color_cycle = [[0, 0, 1, 0.5], [0, 1, 0, 0.5]]\n",
    "\n",
    "review_viewer = napari.view_image(voi, rgb=False)\n",
    "\n",
    "\n",
    "review_layer = review_viewer.add_points(review_points,\n",
    "                    face_color='good_point',\n",
    "                    edge_color=[1, 1, 1, 0],\n",
    "                    face_color_cycle=face_color_cycle,\n",
    "                    name='all points',\n",
    "                    size=3,\n",
    "                    properties=review_properties)\n",
    "\n",
    "\n",
    "# bind a function to toggle the good_point annotation of the selected points\n",
    "@review_viewer.bind_key('c')\n",
    "def toggle_class(review_viewer):\n",
    "    selected_points = np.array(list(review_layer.selected_data))\n",
    "    if len(selected_points) > 0:\n",
    "        print(f\"Toggling {len(selected_points)} points\")\n",
    "        good_point = review_layer.properties['good_point']\n",
    "        good_point[selected_points] = ~good_point[selected_points]\n",
    "        review_layer.properties['good_point'] = good_point\n",
    "        review_layer.refresh_colors(update_color_mapping=False)\n",
    "\n",
    "\n",
    "# bind a function to hide the bad (blue - points)\n",
    "@review_viewer.bind_key('h')\n",
    "def hide_bad_points(review_viewer):\n",
    "    global show_bad_points\n",
    "    if show_bad_points:\n",
    "        review_layer.face_color_cycle = [[0, 0, 1, 0], [0, 1, 0, 1]]\n",
    "        show_bad_points = False\n",
    "    else:\n",
    "        review_layer.face_color_cycle = [[0, 0, 1, 1], [0, 1, 0, 1]]\n",
    "        show_bad_points = True\n",
    "        \n",
    "@review_viewer.bind_key('f')\n",
    "def save_points(review_viewer):\n",
    "\n",
    "    print(\"Saving labeled points to file\")\n",
    "    #save results to files.\n",
    "\n",
    "    fout = output_path + \"/roi_\" + str(roi_idx) + \"/curated_blobs.npz\"\n",
    "    np.savez(fout, coords=review_layer.data, class_label=review_layer.properties['good_point'], \n",
    "                    size=review_layer.size, confidence=review_layer.properties['confidence'],\n",
    "                    threshold=[confidence_t])\n",
    "\n",
    "    print(\"Saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python37464bitvenvvenve089c7a49ef041b79e427c70bd6cfe1b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "sos": {
   "kernels": [
    [
     "cortex-nuclei-count",
     "cortex-nuclei-count",
     "python3",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ],
    [
     "cortex-nuclei-count-please",
     "cortex-nuclei-count-please",
     "python3",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ]
   ],
   "version": "0.21.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
